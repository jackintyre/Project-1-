{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Processing \n",
    "----\n",
    "\n",
    "#### Data cleaning and formatting is done to create Pandas dataframes to be used for mapping and visualization of the data.  The primary data set comes from an api generated by CBS Sports News and hosted by Amazon Web Services.  The data set is a listing of College/University Sports Events that are scheduled to be streamed by video or audio.  The ask by CBS Sports News is to take the API that is generated weekly and create a visualization of the scheduled events to be broadcast to help anticipate staffing needs on a daily basis.  For CBS Sports News, a heat map/and or graphic visualization of the games to be broadcast by specific pub points will be used to deliver this information.   Further analysis of the events data, will be done using information gathered from a listing of Universities and Colleges to get location data to create maps and visualizations of the events held at specific locations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import json as js\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Import API key - usng CBS keys - not used yet\n",
    "#from api_keys import sport_key\n",
    "from config import gkey\n",
    "from config import scorecard_key\n",
    "\n",
    "# Incorporated citipy to determine city based on latitude and longitude\n",
    "from citipy import citipy\n",
    "\n",
    "# Input test file (JSON).\n",
    "input_data_file01=\"Resources/Events.json\"\n",
    "input_data_file02=\"Resources/MERGED2018_19_PP.csv\"\n",
    "output_data_file = \"eventsMaster.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for analyzing / cleaning data\n",
    "\n",
    "Step1 - Capture data from the CBS Sports News API, filter, clean and assemble a dataframe that has school location data and pub points data \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need: \n",
    "'count'  - gives the number of events in the list\n",
    "nested in 'count'\n",
    "'events' - nested\n",
    " by 'contenttype'\n",
    "     'eventstate' 'scheduled'\n",
    "     'eventstatus' 'live'\n",
    "     'eventtype' 'game'\n",
    "     'is_passthrough' 'False'\n",
    "     'prismid': '27a62c10-4a15-42ae-a81b-9b31c346ffb9',  [unique id]\n",
    "     'schedule': {'endtimestamp': 1618181100,\n",
    "                          'starttimebuffer': 0,\n",
    "                          'starttimestamp': 1618163100},\n",
    "     'school': 'nwst',\n",
    "     'school_name': 'Northwestern State University',\n",
    "     'sport': 'm-basebl',\n",
    "     'sport_name': 'Baseball',\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "with open(input_data_file01) as f:\n",
    "  data = js.load(f)\n",
    "#gives a dictionary\n",
    "#data.values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [403]>\n",
      "{\n",
      "    \"message\": \"Forbidden\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#starttime and endtime are in epoch time \n",
    "starttime=1617768000\n",
    "endtime=1618372800\n",
    "#url ='https://ufp5x5qk2i.execute-api.us-east-1.amazonaws.com/prod/eventmanager/events?starttime=1617768000.001&endtime=1618372800'\n",
    "url ='https://ufp5x5qk2i.execute-api.us-east-1.amazonaws.com/prod/eventmanager/events?starttime='+str(starttime)+'&endtime='+str(endtime)\n",
    "\n",
    "#headers pulls api key from config.py, assignes it to x-api-key\n",
    "headers = {\"scorecard_key\": scorecard_key}\n",
    "\n",
    "#assemble request, pulls x-api-key as header to access api\n",
    "req = requests.get(url, headers=headers)\n",
    "print(req)\n",
    "\n",
    "response_json = req.json()\n",
    "print(js.dumps(response_json, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "#pp = pprint.PrettyPrinter(depth=4)\n",
    "#pp.pprint(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way to print\n",
    "#pp.pprint(f'Dictionary comprehension: {data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#checking to remove passthroughs\n",
    "newDict={}\n",
    "print(data['count'])\n",
    "newCount=0\n",
    "#filter out the passthrough records\n",
    "Counts=data['count']\n",
    "#first look for passthrough = True\n",
    "for index in range(1,Counts):\n",
    "    if data['events'][index]['is_passthrough']==False:\n",
    "        newDict=data\n",
    "        newCount= newCount+1\n",
    "    \n",
    "#print(newDict)    \n",
    "print(f'filtered data counts {newCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#create the master filtered data frame\n",
    "ID=[]\n",
    "Type=[]\n",
    "Scheduled=[]\n",
    "Status=[]\n",
    "CType=[]\n",
    "Pass=[]\n",
    "Start=[]\n",
    "End=[]\n",
    "Event_Title=[]\n",
    "School_Name=[]\n",
    "School_Code=[]\n",
    "Game=[]\n",
    "PubPoint=[]\n",
    "\n",
    "\n",
    "for index in range(1,newCount):\n",
    "    try:\n",
    "        ID.append(newDict['events'][index]['prismid'])\n",
    "        Scheduled.append(newDict['events'][index]['eventstate'])\n",
    "        Pass.append(newDict['events'][index]['is_passthrough'])\n",
    "        Start.append(newDict['events'][index]['starttime'])\n",
    "        End.append(newDict['events'][index]['endtime'])\n",
    "        Event_Title.append(newDict['events'][index]['eventtitle'])\n",
    "        School_Name.append(newDict['events'][index]['school_name'])\n",
    "        School_Code.append(newDict['events'][index]['school'])\n",
    "        Game.append(newDict['events'][index]['sport_name'])\n",
    "        \n",
    "    except ValueError:\n",
    "        continue\n",
    "    except KeyError:\n",
    "        print(index)\n",
    "        continue\n",
    "             \n",
    "        \n",
    "  \n",
    "    \n",
    "event_df=pd.DataFrame(ID)\n",
    "event_df['Scheduled']=Scheduled\n",
    "event_df['PassThru']=Pass\n",
    "event_df['Start Time']=Start\n",
    "event_df['End Time']=End\n",
    "event_df['Event']=Event_Title\n",
    "event_df['School Name']=School_Name\n",
    "event_df['School Code']=School_Code\n",
    "event_df['Sport']=Game\n",
    "event_df.rename(columns={0:'ID'},inplace=True)\n",
    "event_df.set_index('ID',inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#get the pass through record values for each prismid\n",
    "with open(input_data_file01) as f:\n",
    "  filter_set = js.load(f)\n",
    "#gives a dictionary\n",
    "filter_set.values()\n",
    "\n",
    "prismid=[]\n",
    "Pass=[]\n",
    "contenttype=[]\n",
    "pubPoint=[]\n",
    "#filter out the passthrough records\n",
    "Counters=filter_set['count']\n",
    "\n",
    "pr_count=0\n",
    "content_count=0\n",
    "pass_count=0\n",
    "pub_count=0\n",
    "#first look for passthrough = True\n",
    "for index in range(1,Counts):\n",
    "   try:     \n",
    "    \n",
    "    if filter_set['events'][index]['is_passthrough']==True:\n",
    "        Pass.append(filter_set['events'][index]['is_passthrough'])\n",
    "        prismid.append(filter_set['events'][index]['prismid'])\n",
    "        contenttype.append(filter_set['events'][index]['contenttype'])\n",
    "        pubPoint.append(filter_set['events'][index]['ingest']['primary']['pub_point'])\n",
    "   except KeyError:\n",
    "        continue\n",
    "\n",
    "count_pid=len(prismid)\n",
    "print(count_pid)        \n",
    "#count_contenttype=len(contenttype)  \n",
    "#count_pass=len(Pass)\n",
    "#print(count_pass)\n",
    "#print(f'pass_throughs are :{Pass}')  \n",
    "count_pubs=len(pubPoint)\n",
    "print(count_pubs)\n",
    "#print(f'pubs are: {pubPoint}')\n",
    "  \n",
    "#print(f'prismids to exclude are :{prismid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#create the pub poing list to merge back to the master filtered data frame\n",
    "counter=0\n",
    "xcount=0\n",
    "prID=[]\n",
    "PP=[]\n",
    "# the pub points\n",
    "for index in range(1,newCount):\n",
    "    if newDict['events'][index]['prismid'] in prismid:\n",
    "        xcount=+1\n",
    "    elif newDict['events'][index]['prismid']not in prismid:\n",
    "        prID.append(newDict['events'][index]['prismid'])\n",
    "        PP.append(newDict['events'][index]['ingest']['primary']['pub_point'])\n",
    "        \n",
    "print(xcount)\n",
    "print(len(prID))  \n",
    "print(len(PP))\n",
    "\n",
    "AddPP_df=pd.DataFrame(prID)\n",
    "AddPP_df['PubPoint']=PP\n",
    "AddPP_df.rename(columns={0:'ID'},inplace=True)\n",
    "AddPP_df.set_index('ID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AddPP_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#this join gets the 558 with 442 pub points\n",
    "working_events=event_df.merge(AddPP_df,how='left', left_on='ID',right_on='ID')\n",
    "#record checks\n",
    "\n",
    "working_events.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_events.tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 - a copy of the dataframe is save to a file \n",
    "#output dataframe to CSV file - passthroughs accunted for - audio shown in pubPoint\n",
    "working_events.to_csv('NewPubPoints_in_events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Data Frame \n",
    "* working_events is saved NewPubPoints_in_events.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XXXXXX\n",
    "* Export the city data into a .csv.\n",
    "* Display the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
